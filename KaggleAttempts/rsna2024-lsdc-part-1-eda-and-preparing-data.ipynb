{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8be5467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T16:19:58.184397Z",
     "iopub.status.busy": "2024-07-30T16:19:58.184005Z",
     "iopub.status.idle": "2024-07-30T16:19:59.449537Z",
     "shell.execute_reply": "2024-07-30T16:19:59.448663Z"
    },
    "papermill": {
     "duration": 1.273782,
     "end_time": "2024-07-30T16:19:59.451922",
     "exception": false,
     "start_time": "2024-07-30T16:19:58.178140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c61073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T16:19:59.462069Z",
     "iopub.status.busy": "2024-07-30T16:19:59.461041Z",
     "iopub.status.idle": "2024-07-30T16:20:06.274409Z",
     "shell.execute_reply": "2024-07-30T16:20:06.273547Z"
    },
    "papermill": {
     "duration": 6.820927,
     "end_time": "2024-07-30T16:20:06.276955",
     "exception": false,
     "start_time": "2024-07-30T16:19:59.456028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rsna_dir = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/\"\n",
    "all_image_dirs = glob(f\"{rsna_dir}/train_images/**/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e7293",
   "metadata": {
    "papermill": {
     "duration": 0.003551,
     "end_time": "2024-07-30T16:20:06.284525",
     "exception": false,
     "start_time": "2024-07-30T16:20:06.280974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Part 1.1, EDA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cebfb31",
   "metadata": {
    "papermill": {
     "duration": 0.00349,
     "end_time": "2024-07-30T16:20:06.291704",
     "exception": false,
     "start_time": "2024-07-30T16:20:06.288214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note: study_id: 3637444890 series_id: 3892989905 (shows neck scan) and 3951475160 (Spinal Canal Stenosis Diagnosis) has an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b2f320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T16:20:06.300834Z",
     "iopub.status.busy": "2024-07-30T16:20:06.300457Z",
     "iopub.status.idle": "2024-07-30T16:20:06.482797Z",
     "shell.execute_reply": "2024-07-30T16:20:06.481956Z"
    },
    "papermill": {
     "duration": 0.189907,
     "end_time": "2024-07-30T16:20:06.485230",
     "exception": false,
     "start_time": "2024-07-30T16:20:06.295323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_series_descriptions = pd.read_csv(f'{rsna_dir}train_series_descriptions.csv')\n",
    "train_label_coordinates = pd.read_csv(f'{rsna_dir}train_label_coordinates.csv')\n",
    "train_y = pd.read_csv(f'{rsna_dir}train.csv')\n",
    "\n",
    "# Removing nan study ids\n",
    "non_nans = list(train_y.dropna()['study_id'].unique())\n",
    "train_series_descriptions = train_series_descriptions[train_series_descriptions['study_id'].isin(non_nans)]\n",
    "train_label_coordinates = train_label_coordinates[train_label_coordinates['study_id'].isin(non_nans)]\n",
    "train_y = train_y[train_y['study_id'].isin(non_nans)]\n",
    "\n",
    "# Removing anomaly\n",
    "train_series_descriptions = train_series_descriptions[train_series_descriptions['study_id']!=3637444890]\n",
    "train_label_coordinates = train_label_coordinates[train_label_coordinates['study_id']!=3637444890]\n",
    "train_y = train_y[train_y['study_id']!=3637444890]\n",
    "\n",
    "train_series_descriptions_val_counts = train_series_descriptions['study_id'].value_counts()\n",
    "\n",
    "# print(\"Brief explanation for each csv:\")\n",
    "# print(f\"- train_series_descriptions.csv contains study/patient ids, the series numbers,\\n  and the MRI image description (denoting the direction of scanning).\")\n",
    "# print(\"  Each row is for one MRI image\")\n",
    "# print(\"- train_label_coordinates.csv contains study/patient ids, the series numbers,\\n  the specific instance number (denoting the nth slice in the 3D MRI image),\")\n",
    "# print(\"  spine levels (l1/l2, etc), and xy coordinates for the condition.\")\n",
    "# print(\"  Each row is for each condition+level diagnosis.\")\n",
    "# print(\"- train.csv contains a column with the study id's and 25 columns for each condition+spine level\\n  whose entries are condition severities for predicting.\")\n",
    "# print(\"  Each row is for one patient\\n\")\n",
    "# print(f\"1. Unique MRI images names:\\n {train_series_descriptions['series_description'].unique()} \\n\")\n",
    "# print(f\"2. Value counts for each image name:\\n {train_series_descriptions['series_description'].value_counts()}\\n\")\n",
    "# print(f\"3. Value counts for each patient id in train_series_descriptions:\\n {train_series_descriptions_val_counts}\")\n",
    "# print(f\"Number of patients with more or less than 3 MRIs: {len(train_series_descriptions_val_counts[train_series_descriptions_val_counts!=3])}\\n\")\n",
    "# print(f\"4. Num patients: {len(train_series_descriptions['study_id'].unique())}\\n\")\n",
    "# print(f\"5. Value counts for each condition:\\n {train_label_coordinates['condition'].value_counts()}\\n\")\n",
    "# print(f\"6. Value counts for each condition by level:\\n {train_label_coordinates[['condition','level']].value_counts().sort_index()}\\n\")\n",
    "# temp_df = train_series_descriptions[['study_id','series_description']].value_counts().sort_index()\n",
    "# sagittal_df = temp_df[temp_df.index.get_level_values(1).isin(['Sagittal T1'])]\n",
    "# axial_df = temp_df[temp_df.index.get_level_values(1).isin(['Axial T2'])]\n",
    "# stir_df = temp_df[temp_df.index.get_level_values(1).isin(['Sagittal T2/STIR'])]\n",
    "# print(f\"7. Study IDs with more than 1 Sagittal T1 Scan:\\n {sagittal_df[sagittal_df>1]}\\n\")\n",
    "# print(f\"8. Study IDs with more than 1 Axial T2 Scan:\\n {axial_df[axial_df>1]}\\n\" )\n",
    "# temp_df = train_label_coordinates\n",
    "# temp_df['series_description'] = temp_df['series_id'].map(train_series_descriptions.drop(columns=['study_id']).set_index('series_id').to_dict()['series_description'])\n",
    "# print(f\"9. Distribution of scan type and condition diagnosis:\\n {temp_df[['series_description','condition']].value_counts().sort_index()}\\n\")\n",
    "# file_num_df = train_series_descriptions\n",
    "# file_num_df = file_num_df.reset_index(drop=True)\n",
    "# file_nums = [len(glob(f\"{rsna_dir}train_images/{row['study_id']}/{row['series_id']}/**\")) for idx,row in file_num_df.iterrows()]\n",
    "# file_num_df = pd.concat([file_num_df,pd.Series(file_nums)],axis=1)\n",
    "# file_num_df.columns = ['study_id','series_id','series_description','file_len']\n",
    "# print(f\"10. Number of image slices by MRI type (max,min,mean):\")\n",
    "# print(f\"{file_num_df.groupby('series_description').max()['file_len']}\\n\")\n",
    "# print(f\"{file_num_df.groupby('series_description').min()['file_len']}\\n\")\n",
    "# print(f\"{file_num_df.groupby('series_description').mean()['file_len']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896d8ab",
   "metadata": {
    "papermill": {
     "duration": 0.003488,
     "end_time": "2024-07-30T16:20:06.492584",
     "exception": false,
     "start_time": "2024-07-30T16:20:06.489096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notes: Duplicate AxialT2s, and duplicate Sagittal T1s need to be filtered out. This will be done by selecting the series_id with the most image slices (so highest resolution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c094b",
   "metadata": {
    "papermill": {
     "duration": 0.003344,
     "end_time": "2024-07-30T16:20:06.499629",
     "exception": false,
     "start_time": "2024-07-30T16:20:06.496285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 1.2, Filtering the duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac41f12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T16:20:06.508328Z",
     "iopub.status.busy": "2024-07-30T16:20:06.507955Z",
     "iopub.status.idle": "2024-07-30T16:20:43.919331Z",
     "shell.execute_reply": "2024-07-30T16:20:43.918439Z"
    },
    "papermill": {
     "duration": 37.418855,
     "end_time": "2024-07-30T16:20:43.922037",
     "exception": false,
     "start_time": "2024-07-30T16:20:06.503182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_num_df = train_series_descriptions\n",
    "file_num_df = file_num_df.reset_index(drop=True)\n",
    "file_nums = [len(glob(f\"{rsna_dir}train_images/{row['study_id']}/{row['series_id']}/**\")) for idx,row in file_num_df.iterrows()]\n",
    "file_num_df = pd.concat([file_num_df,pd.Series(file_nums)],axis=1)\n",
    "file_num_df.columns = ['study_id','series_id','series_description','file_len']\n",
    "file_num_df = file_num_df[file_num_df.index.isin(file_num_df.groupby(['study_id','series_description'])['file_len'].idxmax().unique())]\n",
    "# file_num_df['series_id'].value_counts()[file_num_df['series_id'].value_counts()>1] --> Shows that each series id is unique\n",
    "study_ids = file_num_df['study_id'].unique()\n",
    "series_ids = file_num_df['series_id'].unique()\n",
    "train_series_descriptions = train_series_descriptions[train_series_descriptions['study_id'].isin(study_ids) & train_series_descriptions['series_id'].isin(series_ids)]\n",
    "train_label_coordinates = train_label_coordinates[train_label_coordinates['study_id'].isin(study_ids) & train_label_coordinates['series_id'].isin(series_ids)]\n",
    "train_y = train_y[train_y['study_id'].isin(study_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec27e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T16:20:43.932058Z",
     "iopub.status.busy": "2024-07-30T16:20:43.931259Z",
     "iopub.status.idle": "2024-07-30T16:20:43.937144Z",
     "shell.execute_reply": "2024-07-30T16:20:43.936164Z"
    },
    "papermill": {
     "duration": 0.01296,
     "end_time": "2024-07-30T16:20:43.939247",
     "exception": false,
     "start_time": "2024-07-30T16:20:43.926287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Checking the new dfs:\")\n",
    "# print(f\"1. Unique MRI images names:\\n {train_series_descriptions['series_description'].unique()} \\n\")\n",
    "# print(f\"2. Value counts for each image name:\\n {train_series_descriptions['series_description'].value_counts()}\\n\")\n",
    "# print(f\"3. Value counts for each patient id in train_series_descriptions:\")\n",
    "# print(train_series_descriptions[\"study_id\"].value_counts())\n",
    "# print(f\"4. Num patients: {len(train_series_descriptions['study_id'].unique())}\\n\")\n",
    "# print(f\"5. Value counts for each condition:\\n {train_label_coordinates['condition'].value_counts()}\\n\")\n",
    "# print(f\"6. Value counts for each condition by level:\\n {train_label_coordinates[['condition','level']].value_counts().sort_index()}\\n\")\n",
    "# temp_df = train_series_descriptions[['study_id','series_description']].value_counts().sort_index()\n",
    "# sagittal_df = temp_df[temp_df.index.get_level_values(1).isin(['Sagittal T1'])]\n",
    "# axial_df = temp_df[temp_df.index.get_level_values(1).isin(['Axial T2'])]\n",
    "# stir_df = temp_df[temp_df.index.get_level_values(1).isin(['Sagittal T2/STIR'])]\n",
    "# print(f\"7. Study IDs with more than 1 Sagittal T1 Scan:\\n {sagittal_df[sagittal_df>1]}\\n\")\n",
    "# print(f\"8. Study IDs with more than 1 Axial T2 Scan:\\n {axial_df[axial_df>1]}\\n\" )\n",
    "# temp_df = train_label_coordinates\n",
    "# temp_df['series_description'] = temp_df['series_id'].map(train_series_descriptions.drop(columns=['study_id']).set_index('series_id').to_dict()['series_description'])\n",
    "# print(f\"9. Distribution of scan type and condition diagnosis:\\n {temp_df[['series_description','condition']].value_counts().sort_index()}\\n\")\n",
    "# file_num_df = train_series_descriptions\n",
    "# file_num_df = file_num_df.reset_index(drop=True)\n",
    "# file_nums = [len(glob(f\"{rsna_dir}train_images/{row['study_id']}/{row['series_id']}/**\")) for idx,row in file_num_df.iterrows()]\n",
    "# file_num_df = pd.concat([file_num_df,pd.Series(file_nums)],axis=1)\n",
    "# file_num_df.columns = ['study_id','series_id','series_description','file_len']\n",
    "# print(f\"10. Number of image slices by MRI type (max,min,mean,median):\")\n",
    "# print(f\"{file_num_df.groupby('series_description').max()['file_len']}\\n\")\n",
    "# print(f\"{file_num_df.groupby('series_description').min()['file_len']}\\n\")\n",
    "# print(f\"{file_num_df.groupby('series_description').mean()['file_len']}\\n\")\n",
    "# print(f\"{file_num_df.groupby('series_description').median()['file_len']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed33212",
   "metadata": {
    "papermill": {
     "duration": 0.003525,
     "end_time": "2024-07-30T16:20:43.946605",
     "exception": false,
     "start_time": "2024-07-30T16:20:43.943080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 1.3, Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb34aa8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T16:20:43.956096Z",
     "iopub.status.busy": "2024-07-30T16:20:43.954982Z",
     "iopub.status.idle": "2024-07-30T16:20:43.963652Z",
     "shell.execute_reply": "2024-07-30T16:20:43.962599Z"
    },
    "papermill": {
     "duration": 0.015446,
     "end_time": "2024-07-30T16:20:43.965622",
     "exception": false,
     "start_time": "2024-07-30T16:20:43.950176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def saving_pngs(dcm_files,save_dir):\n",
    "    for j, dcm_file in enumerate(dcm_files):\n",
    "        path = f\"{save_dir}/\"\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)         \n",
    "        dcm = pydicom.dcmread(dcm_file)\n",
    "        image = dcm.pixel_array\n",
    "        path = f\"{save_dir}/{j:03d}.png\"\n",
    "        if image.shape[0]<=512:\n",
    "            resized = cv2.resize(image,(512,512),interpolation = cv2.INTER_CUBIC)\n",
    "            resized = (resized - resized.min())/(resized.max()-resized.min() +1e-6) * 255\n",
    "            cv2.imwrite(path,resized)\n",
    "        else:\n",
    "            resized = cv2.resize(image,(512,512),interpolation = cv2.INTER_AREA)\n",
    "            resized = (resized - resized.min())/(resized.max()-resized.min() +1e-6) * 255\n",
    "            cv2.imwrite(path,resized)\n",
    "def keyFunc(e):\n",
    "    return int(e.split('/')[-1][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0eafc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T16:20:43.975077Z",
     "iopub.status.busy": "2024-07-30T16:20:43.974087Z",
     "iopub.status.idle": "2024-07-30T16:43:30.113599Z",
     "shell.execute_reply": "2024-07-30T16:43:30.112212Z"
    },
    "papermill": {
     "duration": 1366.146993,
     "end_time": "2024-07-30T16:43:30.116382",
     "exception": false,
     "start_time": "2024-07-30T16:20:43.969389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5367/5367 [22:46<00:00,  3.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx,row in tqdm(train_series_descriptions.iterrows(), total=train_series_descriptions.shape[0]):\n",
    "    dcm_files = glob(f\"{rsna_dir}train_images/{row['study_id']}/{row['series_id']}/**\")\n",
    "    dcm_files.sort(key=keyFunc)\n",
    "    num_files = len(dcm_files)\n",
    "    if row['series_description']==\"Axial T2\":\n",
    "        save_dir = f\"cvt_png/{row['study_id']}/Axial T2\"\n",
    "        if num_files<10:\n",
    "            saving_pngs(dcm_files,save_dir)\n",
    "        else:\n",
    "            interval_len = num_files/10\n",
    "            dcm_indexes = [int(np.floor(i*interval_len)) for i in range(10)]\n",
    "            dcm_files = [dcm_files[index] for index in dcm_indexes]\n",
    "            saving_pngs(dcm_files,save_dir)\n",
    "    elif row['series_description']==\"Sagittal T1\":\n",
    "        save_dir = f\"cvt_png/{row['study_id']}/Sagittal T1\"\n",
    "        if num_files<10:\n",
    "            saving_pngs(dcm_files,save_dir)\n",
    "        else:\n",
    "            interval_len = num_files/10\n",
    "            dcm_indexes = [int(np.floor(i*interval_len)) for i in range(10)]\n",
    "            dcm_files = [dcm_files[index] for index in dcm_indexes]\n",
    "            saving_pngs(dcm_files,save_dir)\n",
    "    elif row['series_description']==\"Sagittal T2/STIR\":\n",
    "        save_dir = f\"cvt_png/{row['study_id']}/Sagittal T2\"        \n",
    "        if num_files<10:\n",
    "            saving_pngs(dcm_files,save_dir)\n",
    "        else:\n",
    "            interval_len = num_files/10\n",
    "            dcm_indexes = [int(np.floor(i*interval_len)) for i in range(10)]\n",
    "            dcm_files = [dcm_files[index] for index in dcm_indexes]\n",
    "            saving_pngs(dcm_files,save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838f634",
   "metadata": {
    "papermill": {
     "duration": 0.410369,
     "end_time": "2024-07-30T16:43:30.863440",
     "exception": false,
     "start_time": "2024-07-30T16:43:30.453071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Continuing to training -> https://www.kaggle.com/code/conradtrey/rsna2024-lsdc-part-2-training/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb045884",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T16:43:31.549972Z",
     "iopub.status.busy": "2024-07-30T16:43:31.549086Z",
     "iopub.status.idle": "2024-07-30T16:43:31.555370Z",
     "shell.execute_reply": "2024-07-30T16:43:31.554356Z"
    },
    "papermill": {
     "duration": 0.349386,
     "end_time": "2024-07-30T16:43:31.557627",
     "exception": false,
     "start_time": "2024-07-30T16:43:31.208241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Observing images Axial T2:\n",
    "\n",
    "# print(f\"Examining the extreme case: 4096820034\"+\"\\n\")\n",
    "# print(train_series_descriptions[train_series_descriptions['study_id']==4096820034],\"\\n\")\n",
    "\n",
    "# def display_images(images, title, max_images_per_row=4):\n",
    "#     # Calculate the number of rows needed\n",
    "#     num_images = len(images)\n",
    "#     num_rows = (num_images + max_images_per_row - 1) // max_images_per_row  # Ceiling division\n",
    "\n",
    "#     # Create a subplot grid\n",
    "#     fig, axes = plt.subplots(num_rows, max_images_per_row, figsize=(5, 1.5 * num_rows))\n",
    "    \n",
    "#     # Flatten axes array for easier looping if there are multiple rows\n",
    "#     if num_rows > 1:\n",
    "#         axes = axes.flatten()\n",
    "#     else:\n",
    "#         axes = [axes]  # Make it iterable for consistency\n",
    "\n",
    "#     # Plot each image\n",
    "#     for idx, image in enumerate(images):\n",
    "#         ax = axes[idx]\n",
    "#         ax.imshow(image, cmap='gray')  # Assuming grayscale for simplicity, change cmap as needed\n",
    "#         ax.axis('off')  # Hide axes\n",
    "\n",
    "#     # Turn off unused subplots\n",
    "#     for idx in range(num_images, len(axes)):\n",
    "#         axes[idx].axis('off')\n",
    "#     fig.suptitle(title, fontsize=16)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "\n",
    "# def keyFunc(e:str):\n",
    "#     return int(e.split('/')[-1][:-4])\n",
    "\n",
    "# for idx,row in train_series_descriptions[(train_series_descriptions['study_id']==4096820034) & (train_series_descriptions['series_description']==\"Axial T2\")].iterrows():\n",
    "#     image_dir = f\"{rsna_dir}train_images/{row['study_id']}/{row['series_id']}/**\"\n",
    "#     dcm_dirs = glob(image_dir)\n",
    "#     dcm_dirs.sort(key=keyFunc)\n",
    "#     slices = [pydicom.dcmread(path).pixel_array for path in dcm_dirs]\n",
    "#     display_images(slices, f\"{row['series_id']},{len(slices)}\")\n",
    "\n",
    "# ***Main finding: more or less similar images. Choose the one with most samples.***"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1416.976486,
   "end_time": "2024-07-30T16:43:32.522458",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-30T16:19:55.545972",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
